# Complete Social Media Sentiment Analysis
# Brainwave Matrix Solutions - Task 2
# Save this as: notebooks/complete_sentiment_analysis.ipynb

# Cell 1: Project Setup and Imports
"""
# Social Media Sentiment Analysis
## Brainwave Matrix Solutions - Task 2

**Objective**: Analyze social media sentiment using multiple NLP techniques
**Author**: [Your Name]
**Date**: August 31, 2025
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from wordcloud import WordCloud
import warnings
warnings.filterwarnings('ignore')

# Set up plotting style
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

print("📚 All libraries imported successfully!")

# Cell 2: Load and Explore Data
"""
## 1. Data Loading and Exploration
"""

# Load the analyzed data
df = pd.read_csv('../data/processed/analyzed_sentiment_data.csv')

print(f"📊 Dataset Shape: {df.shape}")
print(f"📅 Date Range: {df['timestamp'].min()} to {df['timestamp'].max()}")
print(f"\n📋 Column Names:")
print(df.columns.tolist())

# Display first few rows
print(f"\n📝 First 5 Rows:")
df.head()

# Cell 3: Data Summary Statistics
"""
## 2. Data Summary and Statistics
"""

print("📊 DATASET OVERVIEW")
print("=" * 50)
print(f"Total Posts Analyzed: {len(df):,}")
print(f"Unique Topics: {df['topic'].nunique()}")
print(f"Date Range: {df['timestamp'].min()} to {df['timestamp'].max()}")

print(f"\n🎯 SENTIMENT DISTRIBUTION")
print("=" * 30)
sentiment_counts = df['ensemble_sentiment'].value_counts()
for sentiment, count in sentiment_counts.items():
    percentage = (count / len(df)) * 100
    print(f"{sentiment.title()}: {count:,} posts ({percentage:.1f}%)")

print(f"\n📱 TOPIC BREAKDOWN")
print("=" * 20)
topic_counts = df['topic'].value_counts()
for topic, count in topic_counts.items():
    percentage = (count / len(df)) * 100
    print(f"{topic}: {count:,} posts ({percentage:.1f}%)")

# Cell 4: Sentiment Distribution Visualization
"""
## 3. Sentiment Distribution Analysis
"""

# Create comprehensive sentiment visualizations
fig, axes = plt.subplots(2, 2, figsize=(16, 12))
fig.suptitle('Sentiment Analysis Results', fontsize=16, fontweight='bold')

# 1. Overall sentiment pie chart
sentiment_counts = df['ensemble_sentiment'].value_counts()
colors = ['#2E8B57', '#DC143C', '#4682B4']
axes[0,0].pie(sentiment_counts.values, labels=sentiment_counts.index, 
             autopct='%1.1f%%', colors=colors, startangle=90)
axes[0,0].set_title('Overall Sentiment Distribution')

# 2. Sentiment by topic
topic_sentiment = pd.crosstab(df['topic'], df['ensemble_sentiment'])
topic_sentiment.plot(kind='bar', ax=axes[0,1], color=colors)
axes[0,1].set_title('Sentiment by Topic')
axes[0,1].set_xlabel('Topic')
axes[0,1].tick_params(axis='x', rotation=45)

# 3. Method comparison
methods = ['textblob_sentiment', 'vader_sentiment', 'ml_sentiment']
method_data = []
for method in methods:
    counts = df[method].value_counts()
    method_data.append([counts.get('positive', 0), counts.get('negative', 0), counts.get('neutral', 0)])

x = np.arange(3)
width = 0.25
axes[1,0].bar(x - width, [m[0] for m in method_data], width, label='Positive', color=colors[0])
axes[1,0].bar(x, [m[1] for m in method_data], width, label='Negative', color=colors[1])
axes[1,0].bar(x + width, [m[2] for m in method_data], width, label='Neutral', color=colors[2])
axes[1,0].set_title('Method Comparison')
axes[1,0].set_xticks(x)
axes[1,0].set_xticklabels(['TextBlob', 'VADER', 'ML'])
axes[1,0].legend()

# 4. Engagement analysis
if 'likes' in df.columns:
    sentiment_engagement = df.groupby('ensemble_sentiment')[['likes', 'retweets']].mean()
    sentiment_engagement.plot(kind='bar', ax=axes[1,1])
    axes[1,1].set_title('Average Engagement by Sentiment')
    axes[1,1].tick_params(axis='x', rotation=0)

plt.tight_layout()
plt.show()

# Cell 5: Temporal Analysis
"""
## 4. Temporal Sentiment Trends
"""

# Convert timestamp to datetime and extract date
df['timestamp'] = pd.to_datetime(df['timestamp'])
df['date'] = df['timestamp'].dt.date

# Daily sentiment analysis
daily_sentiment = df.groupby(['date', 'ensemble_sentiment']).size().unstack(fill_value=0)
daily_sentiment_pct = daily_sentiment.div(daily_sentiment.sum(axis=1), axis=0) * 100

# Create temporal plots
fig, axes = plt.subplots(2, 1, figsize=(15, 10))

# Absolute counts
daily_sentiment.plot(kind='line', ax=axes[0], marker='o', linewidth=2)
axes[0].set_title('Daily Sentiment Counts Over Time')
axes[0].set_ylabel('Number of Posts')
axes[0].legend(title='Sentiment')
axes[0].grid(True, alpha=0.3)

# Percentage distribution
daily_sentiment_pct.plot(kind='area', ax=axes[1], alpha=0.7)
axes[1].set_title('Daily Sentiment Percentage Distribution')
axes[1].set_ylabel('Percentage (%)')
axes[1].legend(title='Sentiment')
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# Cell 6: Advanced Analysis
"""
## 5. Advanced Sentiment Analysis
"""

# Method agreement analysis
print("🔍 METHOD AGREEMENT ANALYSIS")
print("=" * 40)

methods = ['textblob_sentiment', 'vader_sentiment', 'ml_sentiment']
for method in methods:
    agreement = (df[method] == df['ensemble_sentiment']).mean() * 100
    print(f"{method.replace('_', ' ').title()}: {agreement:.1f}% agreement with ensemble")

# Confidence analysis
if 'ensemble_confidence' in df.columns:
    print(f"\n📊 CONFIDENCE STATISTICS")
    print("=" * 25)
    print(f"Mean Confidence: {df['ensemble_confidence'].mean():.3f}")
    print(f"Std Confidence: {df['ensemble_confidence'].std():.3f}")
    
    # High vs low confidence predictions
    high_conf = df[df['ensemble_confidence'] > 0.8]
    low_conf = df[df['ensemble_confidence'] < 0.5]
    print(f"High Confidence (>0.8): {len(high_conf)} posts ({len(high_conf)/len(df)*100:.1f}%)")
    print(f"Low Confidence (<0.5): {len(low_conf)} posts ({len(low_conf)/len(df)*100:.1f}%)")

# Most positive and negative posts
print(f"\n😊 MOST POSITIVE POSTS")
print("=" * 25)
positive_posts = df[df['ensemble_sentiment'] == 'positive'].nlargest(3, 'ensemble_confidence')
for idx, row in positive_posts.iterrows():
    print(f"Topic: {row['topic']} | Confidence: {row['ensemble_confidence']:.3f}")
    print(f"Text: {row['text'][:100]}...")
    print()

print(f"😠 MOST NEGATIVE POSTS")
print("=" * 25)
negative_posts = df[df['ensemble_sentiment'] == 'negative'].nlargest(3, 'ensemble_confidence')
for idx, row in negative_posts.iterrows():
    print(f"Topic: {row['topic']} | Confidence: {row['ensemble_confidence']:.3f}")
    print(f"Text: {row['text'][:100]}...")
    print()

# Cell 7: Word Cloud Generation
"""
## 6. Word Cloud Visualization
"""

# Create word clouds for each sentiment
sentiments = ['positive', 'negative', 'neutral']
colors = ['Greens', 'Reds', 'Blues']

fig, axes = plt.subplots(1, 3, figsize=(18, 6))
fig.suptitle('Word Clouds by Sentiment', fontsize=16, fontweight='bold')

for i, (sentiment, colormap) in enumerate(zip(sentiments, colors)):
    # Get text for this sentiment
    sentiment_text = ' '.join(df[df['ensemble_sentiment'] == sentiment]['cleaned_text'].dropna())
    
    if sentiment_text.strip():
        wordcloud = WordCloud(width=400, height=300, 
                            background_color='white',
                            colormap=colormap,
                            max_words=100,
                            relative_scaling=0.5).generate(sentiment_text)
        
        axes[i].imshow(wordcloud, interpolation='bilinear')
        axes[i].set_title(f'{sentiment.title()} Sentiment')
        axes[i].axis('off')

plt.tight_layout()
plt.show()

# Cell 8: Interactive Plotly Dashboard
"""
## 7. Interactive Dashboard
"""

# Create interactive sentiment timeline
df_daily = df.groupby(['date', 'ensemble_sentiment']).size().unstack(fill_value=0).reset_index()

fig = go.Figure()

for sentiment in ['positive', 'negative', 'neutral']:
    if sentiment in df_daily.columns:
        fig.add_trace(go.Scatter(
            x=df_daily['date'],
            y=df_daily[sentiment],
            mode='lines+markers',
            name=sentiment.title(),
            line=dict(width=3),
            marker=dict(size=8)
        ))

fig.update_layout(
    title='Interactive Sentiment Timeline',
    xaxis_title='Date',
    yaxis_title='Number of Posts',
    hovermode='x unified',
    legend=dict(x=0.02, y=0.98)
)

fig.show()

# Cell 9: Statistical Summary
"""
## 8. Final Statistical Summary
"""

# Create comprehensive summary
summary_stats = {
    'Total Posts Analyzed': len(df),
    'Analysis Period': f"{df['date'].min()} to {df['date'].max()}",
    'Topics Covered': df['topic'].nunique(),
    'Average Confidence': df['ensemble_confidence'].mean() if 'ensemble_confidence' in df.columns else 'N/A'
}

# Method performance
method_performance = {}
for method in ['textblob_sentiment', 'vader_sentiment', 'ml_sentiment']:
    agreement = (df[method] == df['ensemble_sentiment']).mean() * 100
    method_performance[method.replace('_', ' ').title()] = f"{agreement:.1f}%"

# Topic sentiment breakdown
topic_sentiment_summary = pd.crosstab(df['topic'], df['ensemble_sentiment'], normalize='index') * 100

print("📊 FINAL ANALYSIS SUMMARY")
print("=" * 50)

print("\n📈 Basic Statistics:")
for key, value in summary_stats.items():
    print(f"  {key}: {value}")

print("\n🎯 Method Performance:")
for method, performance in method_performance.items():
    print(f"  {method}: {performance} agreement")

print("\n📱 Topic Sentiment Breakdown (%):")
print(topic_sentiment_summary.round(1))

# Save summary
summary_df = pd.DataFrame({
    'Metric': list(summary_stats.keys()) + list(method_performance.keys()),
    'Value': list(summary_stats.values()) + list(method_performance.values())
})

summary_df.to_csv('../results/reports/final_summary.csv', index=False)
print(f"\n✅ Analysis complete! Summary saved to results/reports/final_summary.csv")